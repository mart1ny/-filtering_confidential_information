# ML System Design Doc - [RU]
## Дизайн ML системы — Интеллектуальная система фильтрации конфиденциальной информации / Итерация 1

**Продукт:** Интеллектуальная система фильтрации конфиденциальной информации (далее — “Система”)  
**Итерация:** 1 (MVP для пилота)  
**Дата:** 23.02.2026  
**Владельцы:**  
- Product Owner: (ФИО, роль)  
- Data Scientist / ML Engineer: (ФИО, роль)  
- Tech Lead (Backend/Platform): (ФИО, роль)  
- Security/Compliance: (ФИО, роль)  
- QA: (ФИО, роль)

---

> ## Термины и пояснения
> - Итерация — все работы, выполняемые до старта очередного пилота  
> - БТ — бизнес-требования  
> - EDA — исследовательский анализ данных  
> - PII — персональные данные (Personal Identifiable Information)  
> - DLP — предотвращение утечек данных (Data Loss Prevention)  
> - NER — извлечение сущностей из текста (Named Entity Recognition)

---

# 1. Цели и предпосылки

## 1.1. Зачем идем в разработку продукта?
**Зачем нужен раздел:** фиксирует, какую проблему бизнеса решаем, почему это важно, и что будет считаться успехом итерации в терминах бизнеса.

### Бизнес-цель (Product Owner)
Снизить риск утечек конфиденциальной информации при работе сотрудников с LLM и внешними цифровыми каналами (чаты, тикеты, CRM, почта), чтобы:
- уменьшить вероятность штрафов/юридических рисков и затрат на расследования инцидентов;
- избежать блокировок/ограничений на использование LLM внутри компании из-за рисков безопасности;
- сократить ручную проверку сообщений/файлов и ускорить рабочие процессы.

### Почему станет лучше, чем сейчас, от использования ML (Product Owner & Data Scientist)
Сейчас контроль конфиденциальных данных либо отсутствует, либо реализован простыми правилами (регэкспы) и ручными проверками. Это приводит к:
- пропускам “нетипичных” утечек (перефраз, контекст, нестандартная запись);
- высокой нагрузке на людей при ручных проверках;
- большому числу ложных срабатываний при слишком жестких правилах.

ML (в сочетании с правилами) позволяет:
- распознавать чувствительные фрагменты в свободном тексте (не только “по маске”);
- учитывать контекст и типы сущностей;
- поддерживать расширение на новые типы секретов без переписывания всей логики.

### Что будем считать успехом итерации с точки зрения бизнеса (Product Owner)
Итерация 1 успешна, если система в пилотном контуре:
1) **Ловит почти все действительно опасные случаи**: из 100 документов/сообщений, где реально есть критичные секреты (паспорт/карта/ключи), пропускает не более 5.  
   *Почему именно так:* один пропуск может привести к серьезным последствиям, а 95/100 — практический уровень, который дает заметное снижение инцидентов.
2) **Не мешает работе**: из 10 блокировок минимум 9 должны быть обоснованными.  
   *Почему именно так:* если система часто блокирует “по ошибке”, пользователи обходят контроль или требуют отключения.
3) **Не тормозит пользовательский сценарий**: проверка сообщения/документа занимает “почти мгновенно” — до ~0.2 секунды на типовой объем текста.  
   *Почему именно так:* задержка выше этого порога заметна в чатах и ухудшает принятие продукта.
4) **Держит корпоративный поток**: масштабируется до 1 000 000 документов в сутки (≈ 11–12 в секунду в среднем, с запасом под пики).  
   *Почему именно так:* цель — уровень предприятия и готовность к расширению на несколько каналов.

---

## 1.2. Бизнес-требования и ограничения
**Зачем нужен раздел:** фиксирует краткие БТ и ограничения, чтобы дизайн решения не расходился с ожиданиями и реальностью.

### Краткое описание БТ и ссылки на детальные документы (Product Owner)
**Основные БТ (MVP пилота):**
1) Фильтрация конфиденциальной информации в **тексте** и **файлах**.
2) Интеграция с LLM (через прокси/перехватчик) и внешними сервисами (чат/почта/CRM) через адаптеры.
3) UI + backend для управления и мониторинга (просмотр статистики, кейсов, политик).
4) Уведомления пользователю (почему заблокировано / что делать) и администратору (аудит событий).
5) Тестирование на “обычных” и “обходных” примерах (специальные попытки обойти фильтр).

**Документы/ссылки:** (добавить ссылки компании или репозитория)

### Бизнес-ограничения (Product Owner)
- Система должна работать в защищенном контуре (on-prem/частное облако), т.к. обрабатывает потенциально PII.
- Нельзя сохранять исходные тексты/файлы в логах в открытом виде (только маски/хэши/обрезки по политике).
- Время реакции должно быть достаточным для интерактивных каналов (чат/LLM).
- Поддержка минимум RU/EN.

### Что мы ожидаем от конкретной итерации (Product Owner)
- MVP: текст + базовые файлы (pdf/docx/txt), базовая политика решений (allow/mask/block/review), UI мониторинга, интеграция с одним каналом (например LLM-чат).
- Подготовка к пилоту с понятными метриками успеха и планом расширения.

### Описание бизнес-процесса пилота (Product Owner)
**Как будет использоваться модель в процессе:**
- Сотрудник вводит запрос в LLM-чат/форму отправки.
- Запрос перехватывается прокси, проверяется системой.
- Если найден риск:
  - показываем пользователю причину и действие (исправить/удалить секрет/использовать защищенный канал);
  - логируем событие и уведомляем админа (при высоком риске).
- Если риска нет — запрос уходит в LLM/сервис.

### Что считаем успешным пилотом? (Product Owner)
- Система реально предотвращает передачу чувствительных данных в пилотном канале.
- Пользователи не испытывают значимого ухудшения UX (нет “тормозов”, нет массовых ложных блокировок).
- Администратор видит прозрачный аудит и статистику, может управлять политиками.

---

## 1.3. Что входит в скоуп проекта/итерации, что не входит
**Зачем нужен раздел:** фиксирует границы ответственности команды и предотвращает “расползание” требований.

### На закрытие каких БТ подписываемся в данной итерации (Data Scientist)
**Входит в итерацию 1:**
- Детекция в тексте: PII (ФИО/телефон/email), паспорт РФ (если применимо), банковские карты (с проверкой Luhn), токены/ключи (по паттернам).
- Детекция в файлах: извлечение текста из pdf/docx/txt и применение того же пайплайна.
- Решения: allow / mask / block / review.
- UI: базовый мониторинг + просмотр кейсов + настройка политик.
- Логи/аудит событий в безопасном виде.

### Что не будет закрыто (Data Scientist)
- Полная поддержка OCR по изображениям/сканам (в roadmap, итерация 2+).
- Сложная “коммерческая тайна по смыслу” (требует отдельной постановки и данных).
- 100% покрытие всех форматов файлов (xlsx, pptx, архивы) — после MVP.
- Полная автоматизация разметки без участия экспертов — на MVP допускается частичная ручная разметка и синтетика.

### Описание результата с точки зрения качества кода и воспроизводимости решения (Data Scientist)
- Репозиторий с модульной архитектурой (services + common libs).
- Конфигурации политик отделены от кода (конфиг/БД).
- Версионирование моделей (model registry или минимум семантические версии + артефакты).
- Воспроизводимое обучение (фиксированные датасеты/сплиты, seed, конфиги).
- Набор регрессионных тестов на типы сущностей.

### Описание планируемого технического долга (Data Scientist)
- Возможно отсутствие полноценного model registry/MLflow в MVP (заменяется простым storage + версионирование).
- Первоначально ограниченная оптимизация инференса (без ONNX/квантизации) — включить при росте нагрузки.
- Ограниченный набор форматов файлов и каналов интеграции.

---

## 1.4. Предпосылки решения
**Зачем нужен раздел:** фиксирует допущения, от которых зависит успех — чтобы их можно было проверить и при необходимости пересмотреть.

**Предпосылки:**
1) Большая часть чувствительных данных в пилотных сценариях представлена **в тексте** или в файлах с извлекаемым текстом (pdf/docx/txt).
2) Конфиденциальные сущности можно описать как:
   - форматные (карты/телефоны/email) — ловятся правилами,
   - контекстные (ФИО, “ключи”, неформатные идентификаторы) — ловятся ML.
3) Политика допустимости зависит от канала и роли (например, “в LLM чат — строго”).
4) Доступ к пилотным данным возможен в безопасном контуре и в обезличенном/синтетическом виде для обучения.
5) Нужен механизм “обратной связи” по ошибкам (ложные блокировки/пропуски) для улучшений.

---

# 2. Методология (Data Scientist)

## 2.1. Постановка задачи
**Зачем нужен раздел:** переводит бизнес-задачу в техническую постановку, определяет входы/выходы и тип ML-задачи.

### Тип задачи
Гибридная DLP-система для текста и файлов:
- **NER / sequence labeling** — извлечение сущностей конфиденциальных данных.
- **Document-level decisioning** — решение allow/mask/block/review на основе найденных сущностей + политики.

### Входы
- `content`: текст сообщения или извлеченный текст из файла
- `context`: канал (LLM/chat/email/CRM), пользователь/роль, политика
- `metadata`: размер, язык, источник, идентификаторы транзакции

### Выходы
- `decision`: allow/mask/block/review
- `entities`: список сущностей (тип, позиция, confidence)
- `risk_score`: агрегированная оценка риска (0..1)
- `user_message`: понятное объяснение пользователю
- `audit_event`: запись для админа/мониторинга

---

## 2.2. Блок-схема решения
**Зачем нужен раздел:** показывает end-to-end поток, включая бейзлайн и MVP, чтобы не было разрывов между “моделью” и “системой”.

### Бейзлайн (Baseline) — rules-first
1) Ingress (proxy / adapter)  
2) Extract text (для файлов)  
3) Normalize text (Unicode, пробелы, разделители, homoglyphs-lite)  
4) Rules engine:
   - regex (email/телефон/паспорт/карта)
   - Luhn check для карт
   - simple key/token patterns
5) Policy engine → decision  
6) Notify user/admin + audit log

### Основной MVP — rules + ML
1) Ingress (proxy / adapter)  
2) Extract text (для файлов)  
3) Normalize text  
4) Fast rules engine (как в бейзлайне)  
5) ML NER (transformer) для контекстных сущностей  
6) Aggregation + risk scoring  
7) Policy engine → decision (allow/mask/block/review)  
8) Notify user/admin + audit log  
9) UI: dashboards + кейсы + политики

> Примечание: каскад “сначала правила, потом ML” снижает стоимость и задержку, т.к. большая часть форматных сущностей ловится быстро.

---

## 2.3. Этапы решения задачи
**Зачем нужен раздел:** максимально конкретно описывает этапы работ (по результатам EDA) и что должно быть на выходе каждого этапа. Важно: отдельно описываем baseline и MVP.

### Этап 1. Данные и подготовка данных (Baseline & MVP)
**Цель:** собрать/подготовить данные и определить целевые сущности.

#### 1) Данные и сущности
| Название данных | Есть ли данные в компании (источник/витрина) | Ресурс для получения (роли) | Качество проверено |
|---|---|---|---|
| Логи сообщений LLM/чат | (указать) | DE/Backend/DS | нет |
| Тикеты/CRM комментарии | (указать) | DE/Analyst/DS | нет |
| Корп. письма (метаданные/тексты) | (указать) | Security/DE/DS | нет |
| Файлы-вложения (pdf/docx/txt) | (указать) | DE/DS | нет |
| Синтетические PII примеры | да (генератор) | DS | да |

#### 2) Целевая переменная / разметка
- Для NER: BIO-разметка сущностей (EMAIL, PHONE, PASSPORT_RU, CARD, TOKEN/KEY, PERSON и т.д.)
- Для decisioning: allow/mask/block/review согласно политике

#### 3) Выход этапа
- Спецификация сущностей (data contract): типы, определения, примеры, приоритеты критичности
- Набор данных (обезличенный/синтетический + размеченный сэмпл)
- Сплиты train/val/test + “обходные” тест-наборы
- Базовые отчеты EDA (язык, длины, частоты сущностей, проблемные паттерны)

#### Риски и что делаем
- Риск: мало размеченных данных → синтетика + активное обучение + ручная разметка только сложных кейсов
- Риск: данные нельзя использовать в открытом виде → маскирование, хранение только токенизированных/обезличенных версий

---

### Этап 2. Baseline: rules engine
**Цель:** быстро получить работающий прототип с понятным качеством и скоростью.

**Техника (Baseline):**
- regex для форматных сущностей
- Luhn check для карт
- нормализация пробелов/разделителей
- “homoglyph-lite” (замены O/0, I/1 и т.п. в ограниченных сценариях)

**Метрики (Baseline):**
- Recall по критичным сущностям (паспорт/карта/ключи) на тест-наборе
- Precision на реальном пилотном потоке (shadow mode)

**Выход этапа:**
- rules library + конфиги
- регрессионные тесты
- первые результаты качества и список “что не ловится правилами”

---

### Этап 3. MVP: ML NER + агрегация риска
**Цель:** покрыть контекстные сущности и снизить пропуски/ложные блокировки.

**Техника (MVP):**
- Transformer NER (RuBERT / multilingual BERT) fine-tune
- Постпроцессинг (объединение токенов, фильтры confidence)
- Агрегация риска:
  - веса по типам сущностей (критичные выше)
  - учет количества и близости сущностей

**Формирование выборок:**
- Train/Val/Test: 70/15/15, стратификация по типам сущностей
- Доп. “обходной” набор: пробелы между цифрами, вставки символов, замены

**Метрики и связь с бизнес-результатом:**
- Приоритет: минимизировать пропуски критичных сущностей (это прямой риск утечки)
- Ограничение: не допустить массовых ложных блокировок (иначе продукт отключат)

**Выход этапа:**
- обученная модель NER + артефакты
- отчет об ошибках: пропуски/ложные срабатывания
- рекомендации по улучшению правил/данных/модели

---

### Этап 4. Policy engine + decisioning
**Цель:** перевести детекции в бизнес-решения, зависящие от канала и роли.

**Техника:**
- Матрица политик (channel × role × entity_type → action)
- Действия: allow / mask / block / review
- Шаблоны сообщений пользователю (понятные, без “ML терминов”)

**Выход этапа:**
- конфиг политик (в БД/конфиг-сервисе)
- unit-тесты на политики
- согласование с Security/Compliance

---

### Этап 5. Интеграция, UI, аудит, тестирование “на обход”
**Цель:** сделать продукт, а не только модель.

**Техника:**
- LLM proxy / adapter
- Extractor service для файлов (pdf/docx/txt)
- UI (дашборд, кейсы, политики)
- Уведомления user/admin
- Тестирование:
  - нагрузочное (throughput/latency)
  - качество на “обычных” и “обходных” наборах

**Выход этапа:**
- end-to-end MVP готов к пилоту
- runbooks (инструкции эксплуатации)
- список задач на следующую итерацию

---

# 3. Подготовка пилота

## 3.1. Способ оценки пилота
**Зачем нужен раздел:** описывает дизайн пилота и как будем измерять эффект, чтобы пилот был объективным.

### Дизайн пилота (Product Owner, Data Scientist)
**Режимы:**
1) Shadow mode (1–2 недели): система принимает решения, но не блокирует — собираем статистику и разметку ошибок.
2) Controlled blocking (2–4 недели): блокируем только критичные типы (паспорт/карта/ключи) + мягкие действия mask/review для остальных.

**Единицы оценки:**
- сообщение/документ
- событие “попытка отправки в LLM/канал”
- кейс в UI (для анализа)

---

## 3.2. Что считаем успешным пилотом
**Зачем нужен раздел:** формализует критерии “идем в прод / не идем / что улучшаем”.

### Метрики успеха пилота (Product Owner)
Пилот успешен, если:
1) **Предотвращение утечек:** среди реально “опасных” случаев пропусков ≤ 5% (т.е. ловим ≥ 95 из 100).  
2) **Адекватность блокировок:** среди блокировок доля “по делу” ≥ 90% (не больше 1 ложной на 10 блокировок).  
3) **Пользовательский опыт:** задержка проверки не ощущается пользователем (типично ≤ 0.2 сек).  
4) **Операционная готовность:** администратор видит статистику и причины, может управлять политиками; есть аудит.

---

## 3.3. Подготовка пилота
**Зачем нужен раздел:** фиксирует, что нужно сделать до пилота и какие вычислительные/операционные ограничения учитываем.

### Вычислительная сложность и ограничения (Data Scientist)
- Baseline rules работает на CPU и масштабируется горизонтально.
- MVP NER:
  - стартуем с CPU inference (если throughput ок),
  - при необходимости — выделяем GPU на inference.
- План: замеряем p95 latency и throughput на стенде, определяем необходимость оптимизаций (ONNX/квантование/батчинг).

### Что нужно подготовить
- Тестовые наборы (обычные + обходные)
- Механизм сбора обратной связи (разметка ложных/пропусков в UI)
- План отката (feature flag: выключить блокировки, оставить мониторинг)

---

# 4. Внедрение (для production систем, если требуется)

> Заполнение раздела 4 требуется, если итог итерации предполагает production-развертывание как сервиса.

## 4.1. Архитектура решения
**Зачем нужен раздел:** показывает сервисы, их назначение и интерфейсы, чтобы можно было реализовать и поддерживать систему.

### Компоненты (MVP)
- **Ingress / API Gateway**: принимает запросы от адаптеров
- **Adapter/Proxy**: интеграция с LLM/чатом/CRM/почтой
- **Extractor Service**: извлечение текста из файлов
- **Detector Service**:
  - rules engine
  - ML NER inference
- **Policy/Decision Service**: применение политик и финальное решение
- **Notification Service**: уведомления user/admin
- **Audit Storage**: события, метрики, трассировки
- **Admin UI**: мониторинг, кейсы, политики

### API (черновик)
- `POST /v1/check` — проверка текста/файла → decision + entities  
- `POST /v1/policies` — управление политиками (RBAC)  
- `GET /v1/cases` — кейсы/срабатывания  
- `GET /v1/metrics` — метрики для мониторинга

---

## 4.2. Описание инфраструктуры и масштабируемости
**Зачем нужен раздел:** объясняет выбранную инфраструктуру, масштабирование и почему выбор оптимален.

### Выбор инфраструктуры
- Контейнеризация: Docker
- Оркестрация: Kubernetes (желательно), иначе docker-compose для демо
- Наблюдаемость: Prometheus + Grafana (метрики), Loki/ELK (логи), OpenTelemetry (трейсинг)

### Масштабируемость
- Горизонтальное масштабирование stateless сервисов (ingress, extractor, policy, rules)
- Detector/NER масштабируется отдельным пулом (CPU/GPU) под нагрузку
- Очередь задач (опционально) для тяжелых файлов

### Плюсы / минусы
**Плюсы:** предсказуемое масштабирование, изоляция компонентов, удобные релизы  
**Минусы:** сложнее эксплуатация на малых контурах — решается упрощенным deployment профилем

---

## 4.3. Требования к работе системы
**Зачем нужен раздел:** фиксирует SLA/SLO, throughput и задержку — это критично для UX и доверия.

### SLO (ориентиры для MVP)
- Доступность сервиса: 99.5%
- Latency: p95 ≤ 0.2 сек на типовой текст
- Throughput: готовность к 1 000 000 документов/сутки (≈ 11–12/сек среднее, с запасом на пики)
- Error rate: < 0.1% на запрос

---

## 4.4. Безопасность системы
**Зачем нужен раздел:** т.к. продукт про безопасность, нужно описать угрозы и меры защиты.

### Потенциальные уязвимости
- Обход фильтра с помощью “обфускации” (пробелы, замены символов, кодировки)
- Инъекции/атакующие входы (очень длинные тексты, zip-bomb в файлах)
- Несанкционированный доступ к UI/политикам

### Меры
- Нормализация + лимиты размера контента
- Валидация файлов/типов, ограничения на распаковку
- RBAC, аудит изменений политик
- TLS между компонентами, секреты в Vault/KMS

---

## 4.5. Безопасность данных
**Зачем нужен раздел:** чтобы гарантировать, что система сама не создаёт риск утечки.

### Принципы
- Не сохраняем исходный текст/файлы в логах “как есть”
- Сохраняем:
  - тип сущности
  - маску (например, `****1111`)
  - хэш/идентификатор события
- Разделение доступов: аудиторы видят кейсы, но не сырой контент (если политика запрещает)

---

## 4.6. Издержки
**Зачем нужен раздел:** показывает порядок затрат и позволяет оценить окупаемость.

### Оценка затрат (шаблон)
- Инфраструктура:
  - CPU-узлы для сервисов
  - (опционально) GPU для NER inference
  - мониторинг/логи
- Разработка:
  - Backend + Frontend + ML + DevOps + QA
- Данные:
  - разметка (если требуется)
  - генерация синтетики
- Эксплуатация:
  - поддержка, инциденты, обновления

*(Числа зависят от контура/нагрузки и заполняются после пилотных замеров.)*

---

## 4.5. Integration points
**Зачем нужен раздел:** фиксирует взаимодействия между сервисами и системами, чтобы интеграции были управляемыми.

### Точки интеграции
- LLM proxy: перехват запросов до отправки в LLM
- Чаты/тикеты/CRM: webhook/SDK/прокси
- Почта: SMTP/API (если в scope)
- SSO/IdP: для RBAC в UI

---

## 4.6. Риски
**Зачем нужен раздел:** перечисляет ключевые риски прод-внедрения и как их контролировать.

| Риск | Проявление | Как снижаем |
|---|---|---|
| Много ложных блокировок | пользователи обходят систему | режимы mask/review, тонкая политика по ролям |
| Пропуски критичных данных | инциденты | приоритет recall критичных типов, регрессионные тесты |
| Обфускация/обход | “разбитые” числа, символы-замены | нормализация, robust правила, обходные тесты |
| Высокая задержка | плохой UX | каскад rules→ML, оптимизация инференса |
| Риск утечки в логах | нарушение комплаенса | маскирование/хэширование, контроль доступа |

---

## Приложение: список типов конфиденциальных сущностей (черновик для MVP)
**Критичные (block):**
- PASSPORT_RU (серия/номер и устойчивые паттерны)
- CARD_NUMBER (с Luhn)
- API_KEY / TOKEN / SECRET (по наборам паттернов)

**Средние (mask/review по политике):**
- PHONE, EMAIL
- PERSON (ФИО) — чаще review/mask, зависит от канала

