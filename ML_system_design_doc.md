# ML System Design Doc - [RU]
## Дизайн ML системы — Интеллектуальная система фильтрации конфиденциальной информации

**Продукт:** Интеллектуальная система фильтрации конфиденциальной информации

---

# 1. Цели и предпосылки

## 1.1. Зачем идем в разработку продукта?
**Зачем нужен раздел:** фиксирует, какую проблему бизнеса решаем, почему это важно, и что будет считаться успехом итерации в терминах бизнеса.

### Бизнес-цель (Product Owner)
Снизить риск утечек конфиденциальной информации при работе сотрудников с LLM и внешними цифровыми каналами (чаты, тикеты, CRM, почта), чтобы:
- уменьшить вероятность штрафов/юридических рисков и затрат на расследования инцидентов;
- избежать блокировок/ограничений на использование LLM внутри компании из-за рисков безопасности;
- сократить ручную проверку сообщений/файлов и ускорить рабочие процессы.

### Почему станет лучше, чем сейчас, от использования ML (Product Owner & Data Scientist)
Сейчас контроль конфиденциальных данных либо отсутствует, либо реализован простыми правилами (регэкспы) и ручными проверками. Это приводит к:
- пропускам “нетипичных” утечек (перефраз, контекст, нестандартная запись);
- высокой нагрузке на людей при ручных проверках;
- большому числу ложных срабатываний при слишком жестких правилах.

ML (в сочетании с правилами) позволяет:
- распознавать чувствительные фрагменты в свободном тексте (не только “по маске”);
- учитывать контекст и типы сущностей;
- поддерживать расширение на новые типы секретов без переписывания всей логики.

### Что будем считать успехом итерации с точки зрения бизнеса (Product Owner)
Итерация 1 успешна, если система в пилотном контуре:
1) **Ловит почти все действительно опасные случаи:** из 100 документов/сообщений, где реально есть критичные секреты (паспорт/карта/ключи), пропускает не более 5.  
   *Почему именно так:* один пропуск может привести к серьезным последствиям, а 95/100 — практический уровень, который дает заметное снижение инцидентов.
2) **Не мешает работе:** из 10 блокировок минимум 9 должны быть обоснованными.  
   *Почему именно так:* если система часто блокирует “по ошибке”, пользователи обходят контроль или требуют отключения.
3) **Не тормозит пользовательский сценарий:** проверка сообщения/документа занимает “почти мгновенно” — до ~0.2 секунды на типовой объем текста.  
   *Почему именно так:* задержка выше этого порога заметна в чатах и ухудшает принятие продукта.

---

## 1.2. Бизнес-требования и ограничения
**Зачем нужен раздел:** фиксирует краткие БТ и ограничения, чтобы дизайн решения не расходился с ожиданиями и реальностью.

### Краткое описание БТ и ссылки на детальные документы (Product Owner)
**Основные БТ:**
1) Фильтрация конфиденциальной информации в **тексте** и **файлах**.
2) Интеграция с LLM и внешними сервисами (чат/почта/CRM) через адаптеры.
3) UI + backend для управления и мониторинга (просмотр статистики, кейсов, политик).
4) Уведомления пользователю (почему заблокировано / что делать) и администратору (аудит событий).
5) Тестирование на “обычных” и “обходных” примерах (специальные попытки обойти фильтр).

### Бизнес-ограничения (Product Owner)
- Система должна работать в защищенном контуре, т.к. обрабатывает потенциально персональные данные.
- Нельзя сохранять исходные тексты/файлы в логах в открытом виде.
- Время реакции должно быть достаточным для интерактивных каналов (чат/LLM).
- Поддержка минимум RU/EN.

### Что мы ожидаем от конкретной итерации (Product Owner)
- Текст + базовые файлы (pdf/docx/txt), UI мониторинга, интеграция с одним каналом (например LLM-чат).

### Описание бизнес-процесса пилота (Product Owner)
**Как будет использоваться модель в процессе:**
- Сотрудник вводит запрос в LLM-чат/форму отправки.
- Запрос перехватывается прокси, проверяется системой.
- Если найден риск:
  - показываем пользователю причину и действие (исправить/удалить секрет);
  - логируем событие и уведомляем админа.
- Если риска нет — запрос уходит в LLM/сервис.

### Что считаем успешным пилотом? (Product Owner)
- Система реально предотвращает передачу чувствительных данных в пилотном канале.
- Пользователи не испытывают значимого ухудшения UX (нет “тормозов”, нет массовых ложных блокировок).

---

## 1.3. Что входит в скоуп проекта/итерации, что не входит
**Зачем нужен раздел:** фиксирует границы ответственности команды и предотвращает “расползание” требований.

### На закрытие каких БТ подписываемся в данной итерации (Data Scientist)
**Входит в итерацию 1 (MVP):**
- **Проверка текста на риск конфиденциальности** с помощью BERT-классификатора (ответ “есть риск / нет риска”).
- **Поиск самых очевидных конфиденциальных данных правилами** (шаблоны), чтобы уметь блокировать “самое опасное”:
  - email/телефон,
  - номер банковской карты (с проверкой Luhn),
  - паспорт РФ (по формату),
  - токены/ключи (по типичным паттернам).
- **Проверка файлов:** извлекаем текст из pdf/docx/txt и прогоняем тем же способом (правила + BERT).
- **Интеграция с одним пилотным каналом** (например, LLM-чат через прокси).
- **UI + журнал событий:** статистика, кейсы, причины, настройки политик.
- **Безопасные логи:** без сохранения исходного текста/файлов в открытом виде.

### Что не будет закрыто в итерации 1 (Data Scientist)
- **Точное определение “что именно утекло” с подсветкой всех фрагментов через ML** (это NER) — планируем в итерации 2, когда появится разметка сущностей.
- OCR для изображений/сканов (roadmap, итерация 2+).
- “Коммерческая тайна по смыслу” (требует отдельных данных и правил).
- 100% покрытие всех форматов файлов (xlsx, pptx, архивы).

### Описание результата с точки зрения качества кода и воспроизводимости решения (Data Scientist)
- Репозиторий с модульной архитектурой (services + common libs).
- Настройки политик отделены от кода (конфиг/БД).
- Версионирование модели (хотя бы версии артефактов + конфиги обучения).
- Воспроизводимое обучение (фиксированные сплиты по `id`, seed, конфиги).
- Регрессионные тесты на правила и ключевые сценарии.

### Описание планируемого технического долга (Data Scientist)
- На MVP можем обойтись без полноценного MLflow/model registry (заменяем простым хранилищем и версионированием).
- Оптимизация скорости (ONNX/квантование) — включаем при росте нагрузки.
- Поначалу поддерживаем ограниченный набор каналов и форматов.

---

## 1.4. Предпосылки решения
**Зачем нужен раздел:** фиксирует допущения, от которых зависит успех — чтобы их можно было проверить и при необходимости пересмотреть.

**Предпосылки:**
1) В пилотных сценариях большая часть конфиденциальных данных встречается **в тексте** или в файлах, где можно извлечь текст (pdf/docx/txt).
2) На итерации 1 мы считаем “конфиденциальность” так:
   - **правила** ловят самые очевидные случаи (карта/паспорт/email/телефон/ключи),
   - **BERT** даёт общий риск “похоже на конфиденциальное / не похоже”.
3) Политика действий зависит от канала и роли (например, “в LLM-чат строго”).
4) Для улучшений нужен механизм обратной связи: админ помечает кейсы как “верно/ошибка”.

---

# 2. Методология (Data Scientist)

## 2.1. Постановка задачи
**Зачем нужен раздел:** переводит бизнес-задачу в конкретную ML-постановку: что предсказываем, на каких данных, какие входы/выходы у модели, и как это будет использоваться в системе.

### Тип задачи
Для итерации 1 задача формулируется как **бинарная классификация текста**: определить, содержит ли промт/сообщение конфиденциальную информацию.

- **ML-задача:** бинарная классификация текста (0/1)
- **Модель:** BERT-подобная (например, RuBERT/mBERT/XLM-R — зависит от языков в данных)
- **Цель:** предсказать `is_contains_confidential` ∈ {0, 1}

> Примечание: в датасете целевая переменная — бинарный флаг наличия конфиденциальности. Поэтому в MVP мы решаем именно классификацию, а не извлечение сущностей (NER). Выделение сущностей можно добавить в следующих итерациях, если потребуется точное объяснение “что именно утекло”.

### Данные (что у нас есть)
Датасет синтетический: данные сгенерированы случайно и не содержат реальных персональных данных. Это снижает риски утечки, но важно помнить, что синтетика может отличаться от поведения пользователей в реальности.

**Поля датасета:**
- `id` — идентификатор диалога (позволяет группировать сообщения в одну цепочку).
- `text` — текст промта (основной объект классификации).
- `source` — источник промта (канал/тип источника; может влиять на паттерны текста).
- `conversation` — история диалога (контекст; опционально используется как дополнительный вход).
- `prompt_lang` — язык промта (например, `ru`, `en`; для аналитики/маршрутизации).
- `answer_lang` — язык ответа (скорее аналитический признак; на MVP не обязателен).
- `is_contains_confidential` — целевая метка: `0` нет конфиденциальных данных, `1` есть.

### Входы модели (что подаем в BERT)
**MVP-вариант (самый стабильный):**
- `text` → BERT → вероятность конфиденциальности `p_confidential`

**Расширенный вариант (если контекст реально влияет):**
- `[CONV] последние N реплик из conversation [SEP] [TEXT] text`

### Выходы модели / сервиса
**Выход BERT-классификатора:**
- `p_confidential` — вероятность [0..1]
- `is_contains_confidential_pred` — 0/1 по порогу

**Выход сервиса (для продукта):**
- `decision` (allow / review / block)
- `risk_score` = `p_confidential`
- `user_message` — понятное сообщение пользователю
- `audit_event` — событие для админа/мониторинга (без хранения исходного текста в открытом виде)

---

## 2.2. Блок-схема решения
**Зачем нужен раздел:** показывает end-to-end поток обработки текста/файлов и где именно находится ML, чтобы дизайн был связным, а не “модель отдельно — система отдельно”.

### Бейзлайн (Baseline) — простые правила
Цель бейзлайна: получить быстрый “минимум работающий” контроль, чтобы быстро показать ценность и иметь запасной вариант, если ML временно выключен.

**Поток:**
1) Ingress (proxy / adapter) принимает текст/файл  
2) Если файл → извлечение текста (pdf/docx/txt)  
3) Normalize text (Unicode, пробелы, разделители)  
4) Rules engine (шаблоны на email/телефон/карту/паспорт/ключи + Luhn для карт)  
5) Policy engine → decision  
6) Notify user/admin + audit log  
7) UI показывает статистику и кейсы

### Основной MVP — BERT-классификация + правила
Цель MVP: лучше понимать текст и снижать пропуски/ложные блокировки, где правила не справляются.

**Поток:**
1) Ingress (proxy / adapter)  
2) Extract text (для файлов)  
3) Normalize text  
4) Fast rules engine — ловит очевидные форматные паттерны  
5) BERT classifier → `p_confidential`  
6) Aggregation:
   - если правила нашли критичный паттерн (карта/паспорт/ключ) → риск высокий
   - иначе риск = `p_confidential`
   - если правила и BERT расходятся, приоритет у правил для критичных типов
7) Policy engine → decision (allow/review/block)  
8) Notify user/admin + audit log  
9) UI: dashboards + кейсы + политики

---

## 2.3. Этапы решения задачи
**Зачем нужен раздел:** конкретно описывает этапы работ и что должно быть на выходе каждого этапа.

### Этап 1. Подготовка данных (Baseline & MVP)
**Цель:** подготовить датасет и пайплайн так, чтобы обучение было воспроизводимым, а оценка — честной.

1) Проверка структуры данных: колонки, типы, пустоты, дубликаты, длины текста.  
2) Разделение train/val/test **по `id` (по диалогам)**, а не по строкам.  
3) Базовый анализ данных: языки, источники, баланс классов, длины.  
4) Подготовка наборов тестов: обычные и “обходные” примеры.

**Выход:** data contract + сплиты + тест-наборы.

### Этап 2. Baseline: rules engine
**Цель:** быстро получить стартовое решение и понять, где правила не работают.

**Выход:** библиотека правил + тесты + отчет по ошибкам.

### Этап 3. MVP: BERT-классификация
**Цель:** повысить качество там, где правила недостаточны.

**Выход:** обученная модель + выбранные пороги + отчет по ошибкам.

### Этап 4. Правила принятия решения (allow/review/block)
**Цель:** перевести риск в понятные действия продукта.

**Выход:** спецификация порогов и политик + тексты сообщений пользователю.

### Этап 5. Интеграция, UI, аудит и пилотные тесты
**Цель:** собрать end-to-end систему и подтвердить метрики на пилоте.

**Выход:** MVP готов к пилоту + runbook + план улучшений на итерацию 2.

---

# 3. Подготовка пилота

## 3.1. Как будем проверять пилот
**Зачем нужен раздел:** чтобы пилот был честным: заранее понятно, что измеряем и по каким правилам решаем “успех/не успех”.

### Как пройдет пилот
**Шаг 1 — “наблюдаем, но не блокируем” (1–2 недели):**
- система проверяет сообщения и файлы;
- пишет результаты в журнал и показывает их в интерфейсе;
- не блокирует, чтобы не мешать работе;
- находим ошибки и настраиваем пороги/правила.

**Шаг 2 — “блокируем только самое опасное” (2–4 недели):**
- блокируем только то, что почти наверняка опасно (карта/паспорт/ключи, найденные правилами);
- остальные сомнительные случаи отправляем на проверку (review) или показываем предупреждение.

---

## 3.2. Что считаем успешным пилотом
**Зачем нужен раздел:** чтобы решение “идем в прод / дорабатываем” принималось по цифрам.

Пилот успешен, если выполняются 4 условия (и мы умеем это посчитать):

1) **Система почти не пропускает опасное:**  
   из 100 проверенных вручную случаев, где реально есть конфиденциальные данные, пропускается не больше 5.

2) **Система не блокирует “впустую”:**  
   из 10 случаев, когда система заблокировала сообщение/файл, минимум 9 блокировок подтверждаются ручной проверкой.

3) **Система не тормозит работу:**  
   проверка сообщения/документа происходит почти мгновенно (до ~0.2 секунды на типовой текст).

4) **Админу видно, что происходит:**  
   есть интерфейс и журнал, где видно количество проверок, решений и причины.

**Как получаем “истину” (чтобы метрики были честные):**
- каждую неделю админ/ИБ вручную проверяет выборку кейсов из UI:
  - 200 случайных “разрешенных” (allow) и 200 “заблокированных/на проверке” (block/review),
  - помечает: “конфиденциальное было / не было”.
- по этим отметкам считаем пропуски и ложные блокировки.

---

## 3.3. Что нужно подготовить до пилота
**Зачем нужен раздел:** чтобы пилот не сорвался из-за доступа, логов, тестов и отсутствия плана отката.

### 1) Тесты и примеры
- Набор обычных примеров (реальные формулировки).
- Набор “обходных” примеров (пробелы, тире, замены символов, смешение языков).

### 2) Настройка решений (что делать при риске)
На MVP используем простую логику:
- Если **правила нашли карту/паспорт/ключ** → сразу `block`.
- Иначе используем вероятность BERT (`p_confidential`):
  - `p < 0.30` → `allow`
  - `0.30 ≤ p < 0.70` → `review` (или предупреждение пользователю)
  - `p ≥ 0.70` → `block`
Пороги уточняем по результатам shadow-режима (шаг 1).

### 3) Сбор обратной связи
- В UI админ отмечает: “верно” / “ошибка”.
- Ошибки собираем для доработки правил и дообучения модели.

### 4) План отката
- Один переключатель: **выключить блокировки**, но оставить проверку и сбор статистики.
- Если пошли массовые ложные блокировки — переводим решения в “review”.

---

# 4. Внедрение (для production систем, если требуется)

> Этот раздел нужен, если после пилота планируем запускать систему как постоянный сервис.

## 4.1. Архитектура решения
**Зачем нужен раздел:** чтобы было понятно, из каких частей состоит система и как данные проходят от пользователя до решения.

### Компоненты (MVP)
- **Прокси/адаптер (Adapter/Proxy)** — стоит перед LLM-чатом и перехватывает текст/файлы до отправки.
- **Extractor** — извлекает текст из pdf/docx/txt.
- **Detector** — проверяет контент:
  - **правила** находят самые очевидные опасные паттерны (карта/паспорт/email/телефон/ключи),
  - **BERT** оценивает общий риск “похоже на конфиденциальное / не похоже”.
- **Decision/Policy** — принимает решение (allow/review/block) по правилам + вероятности BERT + политике канала.
- **Notification** — сообщение пользователю + событие админу.
- **Audit + UI** — журнал и интерфейс (статистика, кейсы, причины, настройки политик).

### Как это работает (простыми шагами)
1) Пользователь вводит текст или прикрепляет файл.  
2) Прокси отправляет данные в систему проверки.  
3) Если файл — Extractor достает текст.  
4) Правила ищут “явные” паттерны (например номер карты).  
5) BERT считает вероятность риска `p_confidential`.  
6) Decision принимает решение: правила важнее для критичных случаев, иначе работают пороги BERT.  
7) Пользователь получает понятное сообщение, админ видит событие в UI/журнале.

---

## 4.2. Инфраструктура и масштабирование
**Зачем нужен раздел:** чтобы система выдерживала поток сообщений и работала стабильно.

- Все сервисы запускаются в контейнерах (Docker).
- Можно развернуть в Kubernetes (если нужно масштабирование).
- Масштабируем отдельно Extractor и Detector, потому что они самые нагруженные.

---

## 4.3. Требования к работе системы
**Зачем нужен раздел:** чтобы UX не ухудшился и система не “упала” под нагрузкой.

- Сервис доступен и стабилен под обычной нагрузкой.
- Проверка сообщения/документа происходит почти мгновенно (до ~0.2 секунды на типовой текст).
- Система готова расти до больших объемов (вплоть до 1 млн документов в сутки).

---

## 4.4. Безопасность системы
**Зачем нужен раздел:** мы защищаем конфиденциальные данные, значит сама система должна быть безопасной.

- Ограничиваем размер текста и файлов (защита от “слишком больших входов”).
- Проверяем типы файлов (защита от вредных вложений).
- Доступ к интерфейсу только по ролям (админ/аудитор).

---

## 4.5. Безопасность данных
**Зачем нужен раздел:** чтобы система не стала источником утечек.

- Исходные тексты и файлы **не сохраняем** в логах в открытом виде.
- В журнале храним только:
  - решение (`allow/review/block`),
  - причину (например “похоже на карту” / “высокий риск по модели”),
  - маску (например `****1111`) или хэш,
  - метаданные: время, канал, политика, технический id события.
- Доступ к журналу и UI — только по ролям.